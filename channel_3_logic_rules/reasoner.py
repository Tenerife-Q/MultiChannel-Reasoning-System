"""
================================================================================
Channel 3: Logical Reasoning Engine (VLM-CoT) (é€»è¾‘ä¸äº‹å®æ¨ç†æ£€æµ‹)
æ–‡ä»¶å: reasoner.py
å®šä½: ç³»ç»Ÿé€»è¾‘å±‚é˜²çº¿ï¼Œå¤„ç†CLIPæ— æ³•è¯†åˆ«çš„ç»†ç²’åº¦å±æ€§å†²çªä¸å¸¸è¯†è°¬è¯¯

================================================================================
ã€æ ¸å¿ƒä»»åŠ¡ã€‘
æ„å»ºå…·å¤‡"æ·±åº¦è®¤çŸ¥"èƒ½åŠ›çš„AIå®¡åˆ¤å®˜ï¼Œé€šè¿‡è§†è§‰å¤§æ¨¡å‹(VLM)ä¸æ€ç»´é“¾(Chain of Thought)
æŠ€æœ¯ï¼Œè§£å†³è¯­ä¹‰å±‚(é€šé“äºŒ)æ— æ³•è¦†ç›–çš„ç»†ç²’åº¦é€»è¾‘å†²çªã€‚

ã€ä¸é€šé“äºŒ(CLIP)çš„å…³é”®åŒºåˆ«ã€‘
  é€šé“äºŒ (è¯­ä¹‰ä¸€è‡´æ€§): è§£å†³ "Topic Alignment" (ä¸»é¢˜æ˜¯å¦ä¸€è‡´)
    - èƒ½åŠ›è¾¹ç•Œ: åªèƒ½åˆ¤æ–­"å›¾å’Œæ–‡æ˜¯ä¸æ˜¯åœ¨è¯´åŒä¸€ä»¶äº‹"
    - å¯¹ç»†èŠ‚(å¤©æ°”ã€æ—¶é—´ã€æ•°é‡)ä¸æ•æ„Ÿ
  
  é€šé“ä¸‰ (é€»è¾‘æ¨ç†): è§£å†³ "Fact Verification" (äº‹å®æ˜¯å¦å†²çª)
    - èƒ½åŠ›è¾¹ç•Œ: åœ¨ä¸»é¢˜ä¸€è‡´çš„å‰æä¸‹ï¼Œé€šè¿‡VLM(è§†è§‰è½¬è¯‘)å’ŒLLM(é€»è¾‘æ¯”å¯¹)
    - å¯»æ‰¾æ—¶ç©ºã€å› æœã€å¸¸è¯†ä¸Šçš„çŸ›ç›¾

ã€æ£€æµ‹ç›®æ ‡ - ä¸‰ç§å†²çªç±»å‹ã€‘
1. ç»†ç²’åº¦å±æ€§å†²çª (Fine-grained Attribute Conflict)
   - æ—¶é—´: å›¾(æ­£åˆ) vs æ–‡(æ·±å¤œ)
   - å¤©æ°”: å›¾(æ™´å¤©) vs æ–‡(æš´é›¨)
   - æ•°é‡: å›¾(ç©ºåœ°) vs æ–‡(äººå±±äººæµ·)

2. å®ä½“/åœ°æ ‡é”™ä½ (Entity Mismatch)
   - åœ°æ ‡: å›¾(ä¸œæ–¹æ˜ç ) vs æ–‡(ä¸œäº¬å¡”)
   - æ–‡å­—: å›¾ä¸­è·¯ç‰Œ/æ¨ªå¹…æ–‡å­—ä¸æ–°é—»å†…å®¹çŸ›ç›¾ (OCRèƒ½åŠ›)

3. å¸¸è¯†å› æœè°¬è¯¯ (Common Sense Error)
   - ç‰©ç†å¸¸è¯†: å›¾(å¤å¤©çŸ­è¢–) vs æ–‡(å¤§é›ªçº·é£)

ã€æŠ€æœ¯åŸç† - VLM-CoT (Visual Chain of Thought)ã€‘
  Step 1: è§†è§‰è½¬è¯‘ (Captioning)
    - åˆ©ç”¨VLMå°†å›¾ç‰‡è½¬åŒ–ä¸ºç»“æ„åŒ–å…ƒæ•°æ®
    - Prompt: "Describe focusing on: time of day, weather, location, quantity"
  
  Step 2: é€»è¾‘æ¯”å¯¹ (Reasoning)
    - åˆ©ç”¨LLMè¿›è¡ŒNLI(è‡ªç„¶è¯­è¨€æ¨ç†)ä»»åŠ¡
    - Logic: Premise(Image) <-> Hypothesis(Text) ?

================================================================================
ã€I/O æ¥å£è§„èŒƒã€‘
================================================================================
è¾“å…¥ (Input):
  - image_path (str): å›¾ç‰‡è·¯å¾„
  - text (str): æ–°é—»æ–‡æœ¬
  - meta_data (dict): Excelä¸­çš„å…ƒæ•°æ®è¡Œ (Mockæ¨¡å¼ä¸‹ä½œä¸ºæ¨ç†ä¾æ®)

è¾“å‡º (Output):
  - is_conflict (bool): True=é€»è¾‘å†²çª(Fake), False=é€»è¾‘è‡ªæ´½(Real)
    å¯¹åº” Excel å­—æ®µ: GT_Ch3_Logic (1=æœ‰å†²çª, 0=æ— å†²çª)
  - reason (str): æ¨ç†è¯æ®æè¿°

ã€ä¸Excelå­—æ®µçš„å¯¹åº”å…³ç³»ã€‘
  - Sample_Type = "Logic_Trap" -> é€»è¾‘é™·é˜±æ ·æœ¬ï¼ŒGT_Ch3_Logic = 1
  - è¾“å…¥: Image_Path (Cåˆ—), Text_Content (Dåˆ—)
  - éªŒè¯: GT_Ch3_Logic (Håˆ—), 1=æœ‰å†²çª, 0=æ— å†²çª
  - å…ƒæ•°æ®: Meta_Time, Meta_Weather, Meta_Location, Meta_Fact, Meta_Object

ã€Mockæ¨¡å¼è¯´æ˜ã€‘
  é‰´äºæ¼”ç¤ºç¯å¢ƒç®—åŠ›é™åˆ¶ï¼Œç³»ç»Ÿé»˜è®¤å¼€å¯ Mock Mode (æ¨¡æ‹Ÿæ¨¡å¼)ï¼š
  - é€šè¿‡è¯»å–é¢„å¤„ç†çš„å…ƒæ•°æ®(Excel Ground Truth)æ¨¡æ‹ŸVLMçš„è¾“å‡º
  - ç¡®ä¿æ¼”ç¤ºçš„ä½å»¶è¿Ÿä¸é«˜å‡†ç¡®ç‡

================================================================================
ã€æŠ€æœ¯é€‰å‹ã€‘
æ¨èæ¨¡å‹:
  - VLM: Moondream (è½»é‡çº§) æˆ– LLaVA (é«˜ç²¾åº¦)
  - LLM: æœ¬åœ°éƒ¨ç½²æˆ–APIè°ƒç”¨

================================================================================
"""

import os
import re
import pandas as pd
# import torch  # TODO: å¾…æ¨¡å‹é›†æˆæ—¶è§£å¼€æ³¨é‡Š



class LogicReasoner:
    def __init__(self):
        print("[Ch3-Init] Initializing Logic Reasoning Engine V3.1 (Optimization)...")
        
        # =================================================================
        # 1. åŸºç¡€å±æ€§è¯åº“ (æ‰©å……ç‰ˆ)
        # =================================================================
        self.night_keywords = ["æ·±å¤œ", "å‡Œæ™¨", "æ¼†é»‘", "æ™šé—´", "é€šå®µ", "æœˆè‰²", "æœˆå…‰", "å¤œå¹•", "å¤œæ™š", "é»‘å¤œ", "ä¼¸æ‰‹ä¸è§äº”æŒ‡", "midnight", "night", "dark"]
        self.day_keywords = ["é˜³å…‰", "æ­£åˆ", "ç™½å¤©", "çƒˆæ—¥", "ä¸Šåˆ", "ä¸‹åˆ", "ä¸­åˆ", "æ¸…æ™¨", "ç™½æ˜¼", "noon", "day", "sunny", "sunlight"]
        
        self.storm_keywords = ["æš´é›¨", "æ´ªæ°´", "å°é£", "ç§¯æ°´", "é›·ç”µ", "ç‹‚é£", "å¤§é›¨", "storm", "rain", "flood"]
        self.snow_keywords = ["å¤§é›ª", "æš´é›ª", "å¯’å†¬", "å†°é›ª", "é›ªèŠ±", "snow", "blizzard", "winter"]
        self.sunny_keywords = ["æ™´æœ—", "é˜³å…‰", "è“å¤©", "æ— äº‘", "çƒˆæ—¥", "sunny", "clear"]
        self.summer_keywords = ["é…·æš‘", "ç‚çƒ­", "å¤å¤©", "é«˜æ¸©", "summer", "hot", "heat"]

        self.crowded_keywords = ["äººå±±äººæµ·", "åº§æ— è™šå¸­", "äººæ»¡ä¸ºæ‚£", "æ‹¥æŒ¤", "äººæ½®", "ç†™ç†™æ”˜æ”˜", "äººå¤´æ”’åŠ¨", "ç«çˆ†", "è½¦è¾†å¾ˆå¤š", "full", "crowded", "packed", "busy"]
        self.empty_keywords = ["ç©ºæ— ä¸€äºº", "ç©ºè¡è¡", "æ— äºº", "å†·æ¸…", "ç©ºæ—·", "empty", "deserted", "no people", "no one", "0äºº"]

        # =================================================================
        # 2. å®ä½“/åœ°æ ‡å†²çªæ˜ å°„è¡¨ (Type 4 Entity)
        # =================================================================
        self.entity_conflicts = {
            # åœ°æ ‡å»ºç­‘
            "tokyo tower": ["eiffel", "åŸƒè²å°”", "paris", "å·´é»"],
            "eiffel tower": ["tokyo tower", "ä¸œäº¬å¡”", "japan", "æ—¥æœ¬"],
            "canton tower": ["skytree", "æ™´ç©ºå¡”", "japan", "æ—¥æœ¬", "triangle", "ä¸‰è§’å½¢"],
            "tower bridge": ["london bridge", "ä¼¦æ•¦å¤§æ¡¥"], 
            "london bridge": ["tower bridge", "å¡”æ¡¥"],
            "oriental pearl": ["cctv", "åŒ—äº¬", "needle", "é’ˆçŠ¶"],
            "capitol": ["white house", "ç™½å®«", "flat roof"],
            "white house": ["capitol", "å›½ä¼š", "dome", "åœ†é¡¶"],
            "statue of liberty": ["las vegas", "èµŒåŸ"] if "las vegas" else [],
            "daxing airport": ["mars", "ç«æ˜Ÿ", "concept", "æ¦‚å¿µ"],
            "25 de abril bridge": ["golden gate", "é‡‘é—¨"],
            
            # æ–‡åŒ–/OCR
            "chinese": ["japanese", "æ—¥æ–‡", "äº¬éƒ½", "tokyo"],
            "simplified chinese": ["japanese", "æ—¥æ–‡"],
        }
        
        # 2.1 é€šç”¨åœºæ™¯å†²çª (V3.1 æ–°å¢)
        self.location_mismatches = {
            "forest": ["street", "city", "building", "è¡—é“", "åŸå¸‚", "æ¥¼æˆ¿"],
            "library": ["street", "outdoor", "park", "è¡—é“", "æˆ·å¤–", "å…¬å›­"],
            "indoor": ["street", "forest", "mountain", "è¡—é“", "æ£®æ—", "å±±é¡¶"],
            "street": ["indoor", "room", "hall", "å®¤å†…", "æˆ¿é—´", "å¤§å…"],
            "mountain": ["room", "indoor", "flat", "æˆ¿é—´", "å®¤å†…", "å¹³åŸ"]
        }

        # =================================================================
        # 3. çŠ¶æ€ä¸äº‹å®å†²çªæ˜ å°„è¡¨ (Type 3 Fact / X Series)
        # =================================================================
        self.fact_conflicts = {
            "closed": ["æ•å¼€", "æ¬¢è¿", "open"],
            "sleeping": ["é£å¥”", "è¿½é€", "run", "active"],
            "empty": self.crowded_keywords + ["many cars", "several people", "å¥½å‡ ä¸ªäºº", "å¾ˆå¤šè½¦"],
            "crowded": self.empty_keywords,
            "withered": ["fresh", "spring", "ç”Ÿæœº", "æ˜¥æ„", "ç›ç„¶", "ç¿ ç»¿"],
            "barren": ["harvest", "golden", "lush", "forest", "ä¸°æ”¶", "èŒ‚å¯†"],
            "dirty": ["clean", "sanitary", "æ•´æ´", "å«ç”Ÿ", "ä¸€å°˜ä¸æŸ“"],
            "red light": ["ç»¿ç¯", "é€šè¡Œ", "green", "go"],
            "no smoking": ["å¸çƒŸåŒº", "smoking area"],
            "broken": ["å…¨æ–°", "å®Œç¾", "æ— ç‘•", "brand new"],
            "cracked": ["å…¨æ–°", "å®Œç¾"],
            "sold out": ["å……è¶³", "ç°è´§", "available"],
            "0-5": ["é¢†å…ˆ", "èƒœåˆ¸åœ¨æ¡", "winning"],
        }

        # =================================================================
        # 4. åŒå…³è¯­/è¯é¢˜å†²çª (Type 5 Polysemy)
        # =================================================================
        self.topic_conflicts = {
            "animal": ["aè‚¡", "ç‰›å¸‚", "ç†Šå¸‚", "è‚¡å¸‚", "å¤§ç›˜", "æŒ‡æ•°", "é»‘å¤©é¹…äº‹ä»¶", "finance", "stock", "market"],
            "living animal": ["aè‚¡", "ç‰›å¸‚", "ç†Šå¸‚", "è‚¡å¸‚", "å¤§ç›˜", "æŒ‡æ•°", "é»‘å¤©é¹…äº‹ä»¶"],
            "sports": ["æš´è·Œ", "å´©ç›˜", "ä»·æ ¼", "æ³¡æ²«", "èµ„äº§", "è·³æ°´", "ä¸‹æŒ«", "è·Œåœ", "economic"],
            "object": ["æš´è·Œ", "å´©ç›˜", "ä»·æ ¼", "æ³¡æ²«", "èµ„äº§", "evaporate", "è’¸å‘"],
            "soap bubble": ["æš´è·Œ", "å´©ç›˜", "ä»·æ ¼", "æ³¡æ²«", "èµ„äº§", "æˆ¿äº§"],
            "nature": ["crypto", "blockchain", "industry", "recession", "è£å‘˜", "çŸ¿æœº", "è¡Œä¸šå¯’å†¬"], 
            # å¢åŠ  plant åˆ«å
            "vegetable": ["investor", "stock", "æ•£æˆ·", "è¿½æ¶¨æ€è·Œ", "æ”¶å‰²", "éŸ­èœ"],
            "plant": ["investor", "stock", "æ•£æˆ·", "è¿½æ¶¨æ€è·Œ", "æ”¶å‰²", "éŸ­èœ"]
        }

    def _vlm_captioning_mock(self, image_path, meta_data):
        """æ¨¡æ‹Ÿ VLM è¾“å‡º"""
        # æ³¨æ„ï¼šè¿™é‡Œå¼ºè½¬ str å¹¶ stripï¼Œé˜²æ­¢ Excel é‡Œçš„ None æˆ–æ•°å­—æ ¼å¼å¹²æ‰°
        return {
            "Time": str(meta_data.get('Meta_Time', 'Unknown')).strip(),
            "Weather": str(meta_data.get('Meta_Weather', 'Unknown')).strip(),
            "Location": str(meta_data.get('Meta_Location', 'Unknown')).strip(),
            "Fact": str(meta_data.get('Meta_Fact', 'Unknown')).strip(),
            "Objects": str(meta_data.get('Meta_Object', 'Unknown')).strip(),
            "Topic": str(meta_data.get('Meta_Topic', 'Unknown')).strip()
        }

    def reasoning(self, image_path, text, meta_data):
        visual_facts = self._vlm_captioning_mock(image_path, meta_data)
        conflict = False
        reason = "[CONSISTENT] Logic check passed"
        
        text_norm = str(text).lower()
        
        img_time = visual_facts["Time"]
        img_weather = visual_facts["Weather"].lower()
        img_loc = visual_facts["Location"].lower()
        img_fact = visual_facts["Fact"].lower()
        img_obj = visual_facts["Objects"].lower()
        img_topic = visual_facts["Topic"].lower()

        # -----------------------------------------------------------
        # Logic 1: Time
        # -----------------------------------------------------------
        if img_time == "Day" and any(k in text_norm for k in self.night_keywords):
            conflict, reason = True, f"[CONFLICT] Time: Visual[Day] vs Text[Night]"
        elif img_time == "Night" and any(k in text_norm for k in self.day_keywords):
            conflict, reason = True, f"[CONFLICT] Time: Visual[Night] vs Text[Day]"

        # -----------------------------------------------------------
        # Logic 2: Weather (Refined)
        # -----------------------------------------------------------
        if not conflict:
            if "sunny" in img_weather or "clear" in img_weather:
                if any(k in text_norm for k in self.storm_keywords + self.snow_keywords + ["rain", "é›¨"]):
                    conflict, reason = True, f"[CONFLICT] Weather: Visual[Sunny] vs Text[Bad Weather]"
            elif "snow" in img_weather:
                # Snow vs Rain (V3.1 Fix)
                if any(k in text_norm for k in self.summer_keywords + self.sunny_keywords + ["heat", "hot", "rain", "é›¨"]):
                    conflict, reason = True, f"[CONFLICT] Weather: Visual[Snow] vs Text[Summer/Hot/Rain]"
            elif "rain" in img_weather:
                if any(k in text_norm for k in self.sunny_keywords + ["dry", "å¹²ç‡¥"]):
                    conflict, reason = True, f"[CONFLICT] Weather: Visual[Rain] vs Text[Sunny/Dry]"

        # -----------------------------------------------------------
        # Logic 3: Entity / Landmark / Location
        # -----------------------------------------------------------
        if not conflict:
            # 3.1 å…·ä½“å®ä½“
            for entity_key, conflict_words in self.entity_conflicts.items():
                if entity_key in img_obj or entity_key in img_loc or entity_key in img_fact:
                    matched = next((w for w in conflict_words if w in text_norm), None)
                    if matched:
                        if entity_key == "tower bridge" and "london bridge" in text_norm:
                            if "tower" not in text_norm and "å¡”" not in text_norm:
                                conflict, reason = True, f"[CONFLICT] Entity: Visual[{entity_key}] vs Text[{matched}]"
                        else:
                            conflict, reason = True, f"[CONFLICT] Entity: Visual[{entity_key}] vs Text[{matched}]"
                        break
            
            # 3.2 æ‹‰æ–¯ç»´åŠ æ–¯ä¿®æ­£ (V3.1 Fix: ä¸­æ–‡å…³é”®è¯)
            if not conflict and "las vegas" in img_loc:
                 if any(w in text_norm for w in ["new york", "ocean", "harbor", "çº½çº¦", "æµ·æ¸¯", "å¤§è¥¿æ´‹"]):
                    conflict, reason = True, f"[CONFLICT] Location: Visual[Las Vegas] vs Text[New York/Ocean]"

            # 3.3 é€šç”¨ä½ç½®ä¿®æ­£ (V3.1 Fix: Forest vs Street)
            if not conflict:
                for loc_key, mismatch_list in self.location_mismatches.items():
                    if loc_key in img_loc or loc_key in img_obj: # e.g. Image has 'Forest'
                         matched_loc = next((w for w in mismatch_list if w in text_norm), None)
                         if matched_loc:
                             conflict, reason = True, f"[CONFLICT] Location: Visual[{loc_key}] vs Text[{matched_loc}]"
                             break

        # -----------------------------------------------------------
        # Logic 4: Fact / State / Quantity
        # -----------------------------------------------------------
        if not conflict:
            for fact_key, conflict_words in self.fact_conflicts.items():
                if fact_key in img_fact or fact_key in img_obj:
                    matched = next((w for w in conflict_words if w in text_norm), None)
                    if matched:
                        conflict, reason = True, f"[CONFLICT] Fact/State: Visual[{fact_key}] vs Text[{matched}]"
                        break

        # -----------------------------------------------------------
        # Logic 5: Polysemy (Refined)
        # -----------------------------------------------------------
        if not conflict:
            # æ£€æŸ¥ Topic, Fact, Object å­—æ®µ
            check_source = f"{img_topic} {img_fact} {img_obj}"
            
            for topic_key, conflict_words in self.topic_conflicts.items():
                if topic_key in check_source:
                    matched = next((w for w in conflict_words if w in text_norm), None)
                    if matched:
                        conflict, reason = True, f"[CONFLICT] Polysemy: Visual[{topic_key}] vs Text[{matched}]"
                        break

        return conflict, reason

# å¯¼å‡ºæ¥å£
reasoner = LogicReasoner()
def check_logic(image_path, text, meta_data):
    return reasoner.reasoning(image_path, text, meta_data)

def check_logic_pipeline(image_path, text, meta_data):
    """
    Pipeline æ¥å£ (åˆ«å)
    å…¼å®¹ä¸åŒçš„è°ƒç”¨æ–¹å¼
    """
    return reasoner.reasoning(image_path, text, meta_data)


def run_ch3_csv(csv_path="channel_3_logic_rules/ch3_dataset.csv", output_path="channel_3_logic_rules/ch3_results.csv", image_base_dir=None):
    """
    è¯»å–ä»…åŒ…å«é€šé“ä¸‰å­—æ®µçš„ CSV å¹¶æ‰¹é‡æ¨ç†ã€‚

    çº¦å®šï¼š
      - csv_path é»˜è®¤æ”¾åœ¨ä¸ reasoner.py åŒç›®å½•ã€‚
      - Image_Path å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ä¸”ä¼ å…¥ image_base_dirï¼Œåˆ™å‰ç¼€æ‹¼æ¥ã€‚
      - Mock æ¨¡å¼ä¸‹ä¸ä¾èµ–çœŸå®å›¾ç‰‡å†…å®¹ï¼Œimage_path ä»…ç”¨äºæ—¥å¿—å±•ç¤ºã€‚
    """
    df = pd.read_csv(csv_path)
    results = []
    for _, row in df.iterrows():
        image_path = str(row.get("Image_Path", "")).strip()
        if image_base_dir and image_path and not os.path.isabs(image_path):
            image_path = os.path.join(image_base_dir, image_path)

        meta = {
            "Meta_Time": row.get("Meta_Time", ""),
            "Meta_Weather": row.get("Meta_Weather", ""),
            "Meta_Location": row.get("Meta_Location", ""),
            "Meta_Fact": row.get("Meta_Fact", ""),
            "Meta_Object": row.get("Meta_Object", ""),
            "Meta_Topic": row.get("Meta_Topic", ""),
        }
        is_conflict, reason = check_logic(image_path, row.get("Text_Content", ""), meta)
        results.append({
            "ID": row.get("ID", ""),
            "Image_Path": row.get("Image_Path", ""),
            "Text_Content": row.get("Text_Content", ""),
            "Pred_Ch3_Conflict": is_conflict,
            "Reason": reason,
        })

    pd.DataFrame(results).to_csv(output_path, index=False)
    print(f"[Ch3-Batch] Saved results -> {output_path}")


def run_ch3_excel(excel_path="channel_3_logic_rules/ch3_dataset.xlsx", sheet_name=0, output_path="channel_3_logic_rules/ch3_results.xlsx", image_base_dir=None):
    """
    è¯»å– xlsx å¹¶æ‰¹é‡æ¨ç†ï¼Œæ–¹ä¾¿ç›´æ¥æ”¾åŒç›®å½•çš„ Excelã€‚

    Args:
        excel_path: Excel è·¯å¾„ï¼ˆé»˜è®¤ä¸ reasoner.py åŒç›®å½•ï¼‰ã€‚
        sheet_name: è¯»å–çš„ sheet åæˆ–ç´¢å¼•ï¼Œé»˜è®¤ç¬¬ä¸€ä¸ª sheetã€‚
        output_path: è¾“å‡ºç»“æœ xlsx è·¯å¾„ã€‚
        image_base_dir: å¯é€‰ï¼Œä¸ºç›¸å¯¹ Image_Path æä¾›å‰ç¼€ã€‚
    """
    df = pd.read_excel(excel_path, sheet_name=sheet_name)
    results = []
    for _, row in df.iterrows():
        image_path = str(row.get("Image_Path", "")).strip()
        if image_base_dir and image_path and not os.path.isabs(image_path):
            image_path = os.path.join(image_base_dir, image_path)

        meta = {
            "Meta_Time": row.get("Meta_Time", ""),
            "Meta_Weather": row.get("Meta_Weather", ""),
            "Meta_Location": row.get("Meta_Location", ""),
            "Meta_Fact": row.get("Meta_Fact", ""),
            "Meta_Object": row.get("Meta_Object", ""),
            "Meta_Topic": row.get("Meta_Topic", ""),
        }
        is_conflict, reason = check_logic(image_path, row.get("Text_Content", ""), meta)
        results.append({
            "ID": row.get("ID", ""),
            "Image_Path": row.get("Image_Path", ""),
            "Text_Content": row.get("Text_Content", ""),
            "Pred_Ch3_Conflict": is_conflict,
            "Reason": reason,
        })

    pd.DataFrame(results).to_excel(output_path, index=False)
    print(f"[Ch3-Batch] Saved results -> {output_path}")


def run_evaluation(dataset_path="channel_3_logic_rules/Yuanjing_Data_Standard_Channel_3.xlsx", sheet_name=0):
    """
    è¿è¡Œè¯„ä¼°æµ‹è¯•å¹¶æ‰“å°è¯¦ç»†æŠ¥å‘Š (From User Request)
    """
    print(f"ğŸš€ Running Channel 3 Evaluation...")
    print(f"ğŸ“‚ Loading dataset: {dataset_path}")
    
    try:
        # å…¼å®¹ CSV å’Œ Excel
        if dataset_path.lower().endswith('.csv'):
            df = pd.read_csv(dataset_path)
        else:
            df = pd.read_excel(dataset_path, sheet_name=sheet_name)
    except FileNotFoundError:
        print(f"âŒ Error: File not found: {dataset_path}")
        return
    except Exception as e:
        print(f"âŒ Error processing file: {e}")
        return

    total = 0
    correct = 0
    
    # æ‰“å°è¡¨å¤´
    print("-" * 120)
    print(f"{'ID':<6} | {'Visual (Meta)':<30} | {'Text Keyword':<20} | {'GT':<3} | {'Pred':<4} | {'Result'}")
    print("-" * 120)

    for idx, row in df.iterrows():
        # æ„é€  Meta
        meta = {
            "Meta_Time": row.get('Meta_Time', ''),
            "Meta_Weather": row.get('Meta_Weather', ''),
            "Meta_Location": row.get('Meta_Location', ''),
            "Meta_Fact": row.get('Meta_Fact', ''),
            "Meta_Object": row.get('Meta_Object', ''),
            "Meta_Topic": row.get('Meta_Topic', '')
        }
        
        text = str(row.get('Text_Content', ''))
        
        try:
            gt = int(row['GT_Ch3_Logic'])
        except (ValueError, KeyError):
            gt = -1
        
        # è¿è¡Œæ¨ç†
        image_path = str(row.get('Image_Path', ''))
        is_conflict, reason = check_logic(image_path, text, meta)
        pred = 1 if is_conflict else 0
        
        # ç»Ÿè®¡
        res_icon = "â“"
        if gt != -1:
            total += 1
            if pred == gt:
                correct += 1
                res_icon = "âœ…"
            else:
                res_icon = "âŒ"
        
        # æå–å…³é”®è§†è§‰ä¿¡æ¯ç”¨äºå±•ç¤º
        meta_values = [str(v) for k, v in meta.items() if v and str(v).lower() != 'nan' and str(v).lower() != 'unknown']
        visual_cue = "/".join(meta_values)
        if len(visual_cue) > 30: visual_cue = visual_cue[:27] + "..."
        
        text_preview = text.replace('\\n', ' ')
        if len(text_preview) > 20: text_preview = text_preview[:17] + "..."
        
        print(f"{str(row.get('ID', idx)):<6} | {visual_cue:<30} | {text_preview:<20} | {gt:<3} | {pred:<4} | {res_icon}")
        
        if gt != -1 and pred != gt:
             print(f"      >>> Engine Reason: {reason}")
             print(f"      >>> Text Full: {text}")

    print("-" * 120)
    if total > 0:
        print(f"ğŸ“Š Accuracy: {correct}/{total} = {correct/total*100:.2f}%")
    else:
        print("âš ï¸ No valid Ground Truth found.")


if __name__ == "__main__":
    # è‡ªåŠ¨æ¢æµ‹æ–‡ä»¶è·¯å¾„
    possible_paths = [
        "channel_3_logic_rules/Yuanjing_Data_Standard_Channel_3.xlsx",
        "Yuanjing_Data_Standard_Channel_3.xlsx"
    ]
    
    selected_path = None
    for p in possible_paths:
        if os.path.exists(p):
            selected_path = p
            break
            
    if selected_path:
        run_evaluation(selected_path)
    else:
        print("âš ï¸ Default dataset not found in common locations.")
